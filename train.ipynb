{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode=\"rt\", encoding=\"utf-8\")\n",
    "\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split(\"\\n\")\n",
    "    sents = [i.split(\"\\t\") for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['fra','ita','spa','por']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(lang):\n",
    "    data = read_text(f\"data/{lang}.txt\")\n",
    "    lang_eng = to_lines(data)\n",
    "    lang_eng = array(lang_eng)\n",
    "    lang_eng = lang_eng[:50000,:]\n",
    "\n",
    "    return lang_eng\n",
    "\n",
    "def remove_puntuation(lang_eng):\n",
    "    # Remove punctuation\n",
    "    lang_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in lang_eng[:,0]]\n",
    "    lang_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in lang_eng[:,1]]\n",
    "    return lang_eng\n",
    "\n",
    "def to_lowerCase(lang_eng):\n",
    "    # convert text to lowercase\n",
    "    for i in range(len(lang_eng)):\n",
    "        lang_eng[i,0] = lang_eng[i,0].lower()\n",
    "        lang_eng[i,1] = lang_eng[i,1].lower()\n",
    "    return lang_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(language: str):\n",
    "    lang_eng = get_data(language)\n",
    "    lang_eng = remove_puntuation(lang_eng)\n",
    "    lang_eng = to_lowerCase(lang_eng)\n",
    "    return lang_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def build_lang_tokenizer(lang_eng,language:str):\n",
    "    # prepare data\n",
    "    lang_tokenizer = tokenization(lang_eng[:, 1])\n",
    "    lang_vocab_size = len(lang_tokenizer.word_index) + 1\n",
    "\n",
    "    pickle.dump(lang_tokenizer, open(f\"tokenizers/{language}/{language}_tokenizer.pkl\", \"wb\"))\n",
    "    \n",
    "    return lang_tokenizer, lang_vocab_size\n",
    "\n",
    "def build_english_tokenizer(lang_eng,language:str):\n",
    "    # prepare data\n",
    "    eng_tokenizer = tokenization(lang_eng[:, 0])\n",
    "    eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "    pickle.dump(eng_tokenizer, open(f\"tokenizers/{language}/eng_tokenizer.pkl\", \"wb\"))\n",
    "\n",
    "    return eng_tokenizer, eng_vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def __train_test_split__(lang_eng):\n",
    "    train, test = train_test_split(lang_eng, train_size=0.8, random_state=12)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding=\"post\")\n",
    "    return seq\n",
    "\n",
    "\n",
    "def encode_sequences_data(lang_tokenizer,eng_tokenizer,train,test):\n",
    "    # prepare training data\n",
    "    trainX = encode_sequences(lang_tokenizer, 12, train[:, 1])\n",
    "    trainY = encode_sequences(eng_tokenizer, 12, train[:, 0])\n",
    "\n",
    "    # prepare validation data\n",
    "    testX = encode_sequences(lang_tokenizer, 12, test[:, 1])\n",
    "    testY = encode_sequences(eng_tokenizer, 12, test[:, 0])\n",
    "\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_training(language: str):\n",
    "    lang_eng = preprocessing(language=language)\n",
    "    lang_tokenizer, lang_vocab_size = build_lang_tokenizer(lang_eng,language)\n",
    "    eng_tokenizer, eng_vocab_size = build_english_tokenizer(lang_eng,language)\n",
    "\n",
    "    train, test = __train_test_split__(lang_eng)\n",
    "\n",
    "    trainX, trainY, testX, testY = encode_sequences_data(lang_tokenizer,eng_tokenizer,train,test)\n",
    "\n",
    "    return lang_tokenizer, lang_vocab_size, eng_tokenizer, eng_vocab_size, trainX, trainY, testX, testY\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation_and_training(lang_vocab_size, eng_vocab_size,language:str,trainX,trainY):\n",
    "    def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "        model.add(LSTM(units))\n",
    "        model.add(RepeatVector(out_timesteps))\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "        model.add(Dense(out_vocab, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "    model = define_model(lang_vocab_size, eng_vocab_size, 12, 12, 512)\n",
    "\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "    filename = f\"models/{language}.keras\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filename, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\"\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    history = model.fit(\n",
    "        trainX,\n",
    "        trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "        epochs=30,\n",
    "        batch_size=512,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(language:str):\n",
    "     lang_tokenizer, lang_vocab_size, eng_tokenizer, eng_vocab_size, trainX, trainY, testX, testY = pre_training(language)\n",
    "     model_creation_and_training(lang_vocab_size, eng_vocab_size,language,trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: fra\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.1587\n",
      "Epoch 1: val_loss improved from inf to 2.09508, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 67s 1s/step - loss: 3.1587 - val_loss: 2.0951\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9888\n",
      "Epoch 2: val_loss improved from 2.09508 to 1.94904, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 64s 1s/step - loss: 1.9888 - val_loss: 1.9490\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8860\n",
      "Epoch 3: val_loss improved from 1.94904 to 1.90145, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 64s 1s/step - loss: 1.8860 - val_loss: 1.9014\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8384\n",
      "Epoch 4: val_loss improved from 1.90145 to 1.86850, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 64s 1s/step - loss: 1.8384 - val_loss: 1.8685\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8014\n",
      "Epoch 5: val_loss improved from 1.86850 to 1.84878, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 64s 1s/step - loss: 1.8014 - val_loss: 1.8488\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7710\n",
      "Epoch 6: val_loss improved from 1.84878 to 1.82537, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 65s 1s/step - loss: 1.7710 - val_loss: 1.8254\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7375\n",
      "Epoch 7: val_loss improved from 1.82537 to 1.80268, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 68s 1s/step - loss: 1.7375 - val_loss: 1.8027\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7057\n",
      "Epoch 8: val_loss improved from 1.80268 to 1.77779, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 72s 1s/step - loss: 1.7057 - val_loss: 1.7778\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6701\n",
      "Epoch 9: val_loss improved from 1.77779 to 1.75277, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 64s 1s/step - loss: 1.6701 - val_loss: 1.7528\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6335\n",
      "Epoch 10: val_loss improved from 1.75277 to 1.72380, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1s/step - loss: 1.6335 - val_loss: 1.7238\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5893\n",
      "Epoch 11: val_loss improved from 1.72380 to 1.68380, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 999ms/step - loss: 1.5893 - val_loss: 1.6838\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5328\n",
      "Epoch 12: val_loss improved from 1.68380 to 1.62767, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1s/step - loss: 1.5328 - val_loss: 1.6277\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4659\n",
      "Epoch 13: val_loss improved from 1.62767 to 1.57032, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1s/step - loss: 1.4659 - val_loss: 1.5703\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4041\n",
      "Epoch 14: val_loss improved from 1.57032 to 1.52259, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1s/step - loss: 1.4041 - val_loss: 1.5226\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3454\n",
      "Epoch 15: val_loss improved from 1.52259 to 1.47664, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 996ms/step - loss: 1.3454 - val_loss: 1.4766\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2879\n",
      "Epoch 16: val_loss improved from 1.47664 to 1.43859, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1s/step - loss: 1.2879 - val_loss: 1.4386\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2333\n",
      "Epoch 17: val_loss improved from 1.43859 to 1.40035, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 62s 994ms/step - loss: 1.2333 - val_loss: 1.4004\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1797\n",
      "Epoch 18: val_loss improved from 1.40035 to 1.37203, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 64s 1s/step - loss: 1.1797 - val_loss: 1.3720\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1305\n",
      "Epoch 19: val_loss improved from 1.37203 to 1.33228, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 1.1305 - val_loss: 1.3323\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0814\n",
      "Epoch 20: val_loss improved from 1.33228 to 1.31470, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 997ms/step - loss: 1.0814 - val_loss: 1.3147\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0346\n",
      "Epoch 21: val_loss improved from 1.31470 to 1.27436, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 62s 993ms/step - loss: 1.0346 - val_loss: 1.2744\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9873\n",
      "Epoch 22: val_loss improved from 1.27436 to 1.25081, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 62s 995ms/step - loss: 0.9873 - val_loss: 1.2508\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9403\n",
      "Epoch 23: val_loss improved from 1.25081 to 1.21813, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 62s 995ms/step - loss: 0.9403 - val_loss: 1.2181\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8946\n",
      "Epoch 24: val_loss improved from 1.21813 to 1.19586, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 998ms/step - loss: 0.8946 - val_loss: 1.1959\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8493\n",
      "Epoch 25: val_loss improved from 1.19586 to 1.17172, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 996ms/step - loss: 0.8493 - val_loss: 1.1717\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8025\n",
      "Epoch 26: val_loss improved from 1.17172 to 1.14736, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 62s 993ms/step - loss: 0.8025 - val_loss: 1.1474\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7582\n",
      "Epoch 27: val_loss improved from 1.14736 to 1.12359, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 997ms/step - loss: 0.7582 - val_loss: 1.1236\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7155\n",
      "Epoch 28: val_loss improved from 1.12359 to 1.10487, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 62s 993ms/step - loss: 0.7155 - val_loss: 1.1049\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6750\n",
      "Epoch 29: val_loss improved from 1.10487 to 1.08490, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1000ms/step - loss: 0.6750 - val_loss: 1.0849\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6336\n",
      "Epoch 30: val_loss improved from 1.08490 to 1.07131, saving model to models\\fra.keras\n",
      "63/63 [==============================] - 63s 1000ms/step - loss: 0.6336 - val_loss: 1.0713\n",
      "language: ita\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.8015\n",
      "Epoch 1: val_loss improved from inf to 1.76077, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 61s 914ms/step - loss: 2.8015 - val_loss: 1.7608\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6296\n",
      "Epoch 2: val_loss improved from 1.76077 to 1.58154, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 873ms/step - loss: 1.6296 - val_loss: 1.5815\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5334\n",
      "Epoch 3: val_loss improved from 1.58154 to 1.52729, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 876ms/step - loss: 1.5334 - val_loss: 1.5273\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4689\n",
      "Epoch 4: val_loss improved from 1.52729 to 1.48367, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 877ms/step - loss: 1.4689 - val_loss: 1.4837\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4237\n",
      "Epoch 5: val_loss improved from 1.48367 to 1.44687, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 880ms/step - loss: 1.4237 - val_loss: 1.4469\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3763\n",
      "Epoch 6: val_loss improved from 1.44687 to 1.40104, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 877ms/step - loss: 1.3763 - val_loss: 1.4010\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3226\n",
      "Epoch 7: val_loss improved from 1.40104 to 1.35196, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 877ms/step - loss: 1.3226 - val_loss: 1.3520\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2718\n",
      "Epoch 8: val_loss improved from 1.35196 to 1.30381, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 874ms/step - loss: 1.2718 - val_loss: 1.3038\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2088\n",
      "Epoch 9: val_loss improved from 1.30381 to 1.25022, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 57s 908ms/step - loss: 1.2088 - val_loss: 1.2502\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1480\n",
      "Epoch 10: val_loss improved from 1.25022 to 1.19443, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 56s 882ms/step - loss: 1.1480 - val_loss: 1.1944\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0856\n",
      "Epoch 11: val_loss improved from 1.19443 to 1.14556, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 866ms/step - loss: 1.0856 - val_loss: 1.1456\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0246\n",
      "Epoch 12: val_loss improved from 1.14556 to 1.09358, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 869ms/step - loss: 1.0246 - val_loss: 1.0936\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9622\n",
      "Epoch 13: val_loss improved from 1.09358 to 1.03735, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 865ms/step - loss: 0.9622 - val_loss: 1.0374\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9022\n",
      "Epoch 14: val_loss improved from 1.03735 to 0.98759, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 874ms/step - loss: 0.9022 - val_loss: 0.9876\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8426\n",
      "Epoch 15: val_loss improved from 0.98759 to 0.94033, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 874ms/step - loss: 0.8426 - val_loss: 0.9403\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7861\n",
      "Epoch 16: val_loss improved from 0.94033 to 0.89782, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 869ms/step - loss: 0.7861 - val_loss: 0.8978\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7301\n",
      "Epoch 17: val_loss improved from 0.89782 to 0.85668, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 874ms/step - loss: 0.7301 - val_loss: 0.8567\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6784\n",
      "Epoch 18: val_loss improved from 0.85668 to 0.81795, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 864ms/step - loss: 0.6784 - val_loss: 0.8179\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6249\n",
      "Epoch 19: val_loss improved from 0.81795 to 0.78058, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 867ms/step - loss: 0.6249 - val_loss: 0.7806\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5745\n",
      "Epoch 20: val_loss improved from 0.78058 to 0.75259, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 865ms/step - loss: 0.5745 - val_loss: 0.7526\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5287\n",
      "Epoch 21: val_loss improved from 0.75259 to 0.71650, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 866ms/step - loss: 0.5287 - val_loss: 0.7165\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4847\n",
      "Epoch 22: val_loss improved from 0.71650 to 0.68706, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 55s 875ms/step - loss: 0.4847 - val_loss: 0.6871\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4423\n",
      "Epoch 23: val_loss improved from 0.68706 to 0.65873, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 864ms/step - loss: 0.4423 - val_loss: 0.6587\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4054\n",
      "Epoch 24: val_loss improved from 0.65873 to 0.63547, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 864ms/step - loss: 0.4054 - val_loss: 0.6355\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3709\n",
      "Epoch 25: val_loss improved from 0.63547 to 0.61530, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 865ms/step - loss: 0.3709 - val_loss: 0.6153\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3411\n",
      "Epoch 26: val_loss improved from 0.61530 to 0.59599, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 863ms/step - loss: 0.3411 - val_loss: 0.5960\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3124\n",
      "Epoch 27: val_loss improved from 0.59599 to 0.57747, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 863ms/step - loss: 0.3124 - val_loss: 0.5775\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2873\n",
      "Epoch 28: val_loss improved from 0.57747 to 0.56343, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 865ms/step - loss: 0.2873 - val_loss: 0.5634\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2635\n",
      "Epoch 29: val_loss improved from 0.56343 to 0.54969, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 864ms/step - loss: 0.2635 - val_loss: 0.5497\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2426\n",
      "Epoch 30: val_loss improved from 0.54969 to 0.53942, saving model to models\\ita.keras\n",
      "63/63 [==============================] - 54s 864ms/step - loss: 0.2426 - val_loss: 0.5394\n",
      "language: spa\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.4738\n",
      "Epoch 1: val_loss improved from inf to 2.37400, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 71s 1s/step - loss: 3.4738 - val_loss: 2.3740\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.2539\n",
      "Epoch 2: val_loss improved from 2.37400 to 2.21536, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 2.2539 - val_loss: 2.2154\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1602\n",
      "Epoch 3: val_loss improved from 2.21536 to 2.17113, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 2.1602 - val_loss: 2.1711\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1061\n",
      "Epoch 4: val_loss improved from 2.17113 to 2.12784, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 2.1061 - val_loss: 2.1278\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0699\n",
      "Epoch 5: val_loss improved from 2.12784 to 2.11528, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 2.0699 - val_loss: 2.1153\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0421\n",
      "Epoch 6: val_loss improved from 2.11528 to 2.10001, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 2.0421 - val_loss: 2.1000\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0123\n",
      "Epoch 7: val_loss improved from 2.10001 to 2.06613, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 2.0123 - val_loss: 2.0661\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9717\n",
      "Epoch 8: val_loss improved from 2.06613 to 2.03398, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.9717 - val_loss: 2.0340\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9317\n",
      "Epoch 9: val_loss improved from 2.03398 to 2.00975, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.9317 - val_loss: 2.0097\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8950\n",
      "Epoch 10: val_loss improved from 2.00975 to 1.98515, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.8950 - val_loss: 1.9852\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8630\n",
      "Epoch 11: val_loss improved from 1.98515 to 1.96933, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.8630 - val_loss: 1.9693\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8309\n",
      "Epoch 12: val_loss improved from 1.96933 to 1.94347, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.8309 - val_loss: 1.9435\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7937\n",
      "Epoch 13: val_loss improved from 1.94347 to 1.92446, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.7937 - val_loss: 1.9245\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7526\n",
      "Epoch 14: val_loss improved from 1.92446 to 1.88821, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 68s 1s/step - loss: 1.7526 - val_loss: 1.8882\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7014\n",
      "Epoch 15: val_loss improved from 1.88821 to 1.84381, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.7014 - val_loss: 1.8438\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6445\n",
      "Epoch 16: val_loss improved from 1.84381 to 1.79877, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.6445 - val_loss: 1.7988\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5812\n",
      "Epoch 17: val_loss improved from 1.79877 to 1.75517, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.5812 - val_loss: 1.7552\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5146\n",
      "Epoch 18: val_loss improved from 1.75517 to 1.71100, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.5146 - val_loss: 1.7110\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4483\n",
      "Epoch 19: val_loss improved from 1.71100 to 1.67347, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.4483 - val_loss: 1.6735\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3865\n",
      "Epoch 20: val_loss improved from 1.67347 to 1.62589, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.3865 - val_loss: 1.6259\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3238\n",
      "Epoch 21: val_loss improved from 1.62589 to 1.58723, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 68s 1s/step - loss: 1.3238 - val_loss: 1.5872\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2642\n",
      "Epoch 22: val_loss improved from 1.58723 to 1.55438, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 69s 1s/step - loss: 1.2642 - val_loss: 1.5544\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2085\n",
      "Epoch 23: val_loss improved from 1.55438 to 1.52947, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 67s 1s/step - loss: 1.2085 - val_loss: 1.5295\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1549\n",
      "Epoch 24: val_loss improved from 1.52947 to 1.49466, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.1549 - val_loss: 1.4947\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1022\n",
      "Epoch 25: val_loss improved from 1.49466 to 1.46654, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.1022 - val_loss: 1.4665\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0507\n",
      "Epoch 26: val_loss improved from 1.46654 to 1.43498, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.0507 - val_loss: 1.4350\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9993\n",
      "Epoch 27: val_loss improved from 1.43498 to 1.40633, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.9993 - val_loss: 1.4063\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9512\n",
      "Epoch 28: val_loss improved from 1.40633 to 1.38749, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 67s 1s/step - loss: 0.9512 - val_loss: 1.3875\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9035\n",
      "Epoch 29: val_loss improved from 1.38749 to 1.36996, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.9035 - val_loss: 1.3700\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8615\n",
      "Epoch 30: val_loss improved from 1.36996 to 1.34289, saving model to models\\spa.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.8615 - val_loss: 1.3429\n",
      "language: por\n",
      "Epoch 1/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.1552\n",
      "Epoch 1: val_loss improved from inf to 2.10245, saving model to models\\por.keras\n",
      "63/63 [==============================] - 70s 1s/step - loss: 3.1552 - val_loss: 2.1025\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9944\n",
      "Epoch 2: val_loss improved from 2.10245 to 1.95920, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.9944 - val_loss: 1.9592\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9044\n",
      "Epoch 3: val_loss improved from 1.95920 to 1.91708, saving model to models\\por.keras\n",
      "63/63 [==============================] - 65s 1s/step - loss: 1.9044 - val_loss: 1.9171\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8541\n",
      "Epoch 4: val_loss improved from 1.91708 to 1.88731, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.8541 - val_loss: 1.8873\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8266\n",
      "Epoch 5: val_loss improved from 1.88731 to 1.87377, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.8266 - val_loss: 1.8738\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7996\n",
      "Epoch 6: val_loss improved from 1.87377 to 1.84420, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.7996 - val_loss: 1.8442\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7590\n",
      "Epoch 7: val_loss improved from 1.84420 to 1.80364, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.7590 - val_loss: 1.8036\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7101\n",
      "Epoch 8: val_loss improved from 1.80364 to 1.76379, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.7101 - val_loss: 1.7638\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6643\n",
      "Epoch 9: val_loss improved from 1.76379 to 1.72014, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.6643 - val_loss: 1.7201\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6057\n",
      "Epoch 10: val_loss improved from 1.72014 to 1.66202, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.6057 - val_loss: 1.6620\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5355\n",
      "Epoch 11: val_loss improved from 1.66202 to 1.59883, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.5355 - val_loss: 1.5988\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4666\n",
      "Epoch 12: val_loss improved from 1.59883 to 1.54495, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.4666 - val_loss: 1.5449\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4027\n",
      "Epoch 13: val_loss improved from 1.54495 to 1.50063, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.4027 - val_loss: 1.5006\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3381\n",
      "Epoch 14: val_loss improved from 1.50063 to 1.44123, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.3381 - val_loss: 1.4412\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2692\n",
      "Epoch 15: val_loss improved from 1.44123 to 1.39047, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.2692 - val_loss: 1.3905\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2015\n",
      "Epoch 16: val_loss improved from 1.39047 to 1.34475, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.2015 - val_loss: 1.3447\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1411\n",
      "Epoch 17: val_loss improved from 1.34475 to 1.29520, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.1411 - val_loss: 1.2952\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0805\n",
      "Epoch 18: val_loss improved from 1.29520 to 1.25400, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.0805 - val_loss: 1.2540\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0244\n",
      "Epoch 19: val_loss improved from 1.25400 to 1.21526, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 1.0244 - val_loss: 1.2153\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9709\n",
      "Epoch 20: val_loss improved from 1.21526 to 1.17945, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.9709 - val_loss: 1.1795\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9204\n",
      "Epoch 21: val_loss improved from 1.17945 to 1.15071, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.9204 - val_loss: 1.1507\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8729\n",
      "Epoch 22: val_loss improved from 1.15071 to 1.12130, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.8729 - val_loss: 1.1213\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8261\n",
      "Epoch 23: val_loss improved from 1.12130 to 1.08903, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.8261 - val_loss: 1.0890\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7807\n",
      "Epoch 24: val_loss improved from 1.08903 to 1.06247, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.7807 - val_loss: 1.0625\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7411\n",
      "Epoch 25: val_loss improved from 1.06247 to 1.03623, saving model to models\\por.keras\n",
      "63/63 [==============================] - 65s 1s/step - loss: 0.7411 - val_loss: 1.0362\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6974\n",
      "Epoch 26: val_loss improved from 1.03623 to 1.01626, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.6974 - val_loss: 1.0163\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6596\n",
      "Epoch 27: val_loss improved from 1.01626 to 0.99864, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.6596 - val_loss: 0.9986\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6219\n",
      "Epoch 28: val_loss improved from 0.99864 to 0.97817, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.6219 - val_loss: 0.9782\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5870\n",
      "Epoch 29: val_loss improved from 0.97817 to 0.96209, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.5870 - val_loss: 0.9621\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5530\n",
      "Epoch 30: val_loss improved from 0.96209 to 0.94871, saving model to models\\por.keras\n",
      "63/63 [==============================] - 66s 1s/step - loss: 0.5530 - val_loss: 0.9487\n"
     ]
    }
   ],
   "source": [
    "for lang in langs:\n",
    "    print(f\"language: {lang}\")\n",
    "    main(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
